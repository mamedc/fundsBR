{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Brazilian funds allocation\n",
    "Data source: http://dados.cvm.gov.br/dataset/fi-doc-cda\n",
    "\n",
    "Data description: http://cvmweb.cvm.gov.br/SWB/Sistemas/SCW/PadroesXML/PadraoXMLCDANetV4.aspx\n",
    "\n",
    "Data description version: 4.0\n",
    "\n",
    "Download date: 2018-09-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script:\n",
    "* load zip files\n",
    "* check for columns inconsistencies along files\n",
    "* merge data into BLC and PL dataframes. For the BLC, it is divided by block number\n",
    "* save dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "date = '2018_09_21'\n",
    "homePath = 'C:/Users/Mamed/Python4DS/'\n",
    "projPath = homePath + 'FundsBR/'\n",
    "dataPath = projPath + 'Data_' + date + '/'\n",
    "unzipTemp = projPath + 'unzipTemp/'\n",
    "strucPath = projPath + 'Structures_' + date + '/'\n",
    "libsPath = projPath + 'Libs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load my libraries\n",
    "exec(open(libsPath + 'fundsLib.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip data\n",
    "# Unziped files will be created at 'unzipTemp' directory\n",
    "\n",
    "# Create directory to unzip data\n",
    "if not os.path.exists(unzipTemp):\n",
    "    os.makedirs(unzipTemp)\n",
    "else:\n",
    "    print('Error: folder already existis.')\n",
    "    \n",
    "# Unzip\n",
    "zFiles = [f for f in os.listdir(dataPath) if os.path.isfile(os.path.join(dataPath, f))]\n",
    "for f in zFiles:\n",
    "    zip_ref = zipfile.ZipFile(dataPath + f, 'r')\n",
    "    zip_ref.extractall(unzipTemp)\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check files names\n",
    "\n",
    "unzFiles = [f for f in os.listdir(unzipTemp) if os.path.isfile(os.path.join(unzipTemp, f))]\n",
    "for f in unzFiles:\n",
    "    \n",
    "    s = f.split('_')\n",
    "    \n",
    "    # Check CDA, FI, BLC and PL\n",
    "    if (s[0] != 'cda') | (s[1] != 'fi') | (not ((s[2] != 'BLC') | (s[2] != 'PL'))): \n",
    "        raise ValueError('Wrong file name: %s' % f)\n",
    "    \n",
    "    # BLC\n",
    "    if s[2] == 'BLC':\n",
    "        \n",
    "        # Block\n",
    "        if int(s[3]) not in list(range(1,9)):\n",
    "            raise ValueError('Block number error: %s' % f)\n",
    "        \n",
    "        # Year and CSV\n",
    "        sBLC = s[4].split('.')\n",
    "        if len(sBLC[0]) == 4 & (int(sBLC[0]) not in list(range(2005,2018))):\n",
    "            raise ValueError('Year error: %s' % f)\n",
    "        if len(sBLC[0]) == 5 & (int(sBLC[0][:4]) != 2018):\n",
    "            raise ValueError('Year error: %s' % f)\n",
    "        if sBLC[1] != 'csv':\n",
    "            raise ValueError('File type error: %s' % f)\n",
    "     \n",
    "    # PL\n",
    "    if s[2] == 'PL':\n",
    "        \n",
    "        # Year and CSV\n",
    "        sPL = s[3].split('.')\n",
    "        if len(sPL[0]) == 4 & (int(sPL[0]) not in list(range(2005,2018))):\n",
    "            raise ValueError('Year error: %s' % f)\n",
    "        if len(sPL[0]) == 5 & (int(sPL[0][:4]) != 2018):\n",
    "            raise ValueError('Year error: %s' % f)\n",
    "        if sPL[1] != 'csv':\n",
    "            raise ValueError('File type error: %s' % f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True True True True True True\n"
     ]
    }
   ],
   "source": [
    "# Check columns conformity for BLC type\n",
    "\n",
    "blc1Head = []\n",
    "blc2Head = []\n",
    "blc3Head = []\n",
    "blc4Head = []\n",
    "blc5Head = []\n",
    "blc6Head = []\n",
    "blc7Head = []\n",
    "blc8Head = []\n",
    "\n",
    "for f in unzFiles:\n",
    "    s = f.split('_')\n",
    "    \n",
    "    # Type (BLC or PL)\n",
    "    fType = s[2]\n",
    "    \n",
    "    # For BLC type\n",
    "    if fType == 'BLC':\n",
    "        \n",
    "        # Block\n",
    "        fBlk = int(s[3])\n",
    "        \n",
    "        # Year\n",
    "        fYear = s[4].split('.')[0]\n",
    "        \n",
    "        if len(fYear) == 4: # Year <= 2017\n",
    "            fMonth = None\n",
    "            fYear = int(fYear)\n",
    "        \n",
    "        else: # Year = 2018\n",
    "            fMonth = int(fYear[-2:])\n",
    "            fYear = int(fYear[:4])\n",
    "        \n",
    "        # Read file head\n",
    "        df_ = pd.read_csv(unzipTemp + f, sep = ';', \n",
    "                 encoding = 'ISO-8859-1', \n",
    "                 low_memory = False, \n",
    "                 nrows = 1)\n",
    "        \n",
    "        # Append head to respective block\n",
    "        if fBlk == 1: blc1Head.append(list(df_.keys()))\n",
    "        if fBlk == 2: blc2Head.append(list(df_.keys()))\n",
    "        if fBlk == 3: blc3Head.append(list(df_.keys()))\n",
    "        if fBlk == 4: blc4Head.append(list(df_.keys()))\n",
    "        if fBlk == 5: blc5Head.append(list(df_.keys()))\n",
    "        if fBlk == 6: blc6Head.append(list(df_.keys()))\n",
    "        if fBlk == 7: blc7Head.append(list(df_.keys()))\n",
    "        if fBlk == 8: blc8Head.append(list(df_.keys()))\n",
    "\n",
    "# Arrange\n",
    "blc1Head = np.array(blc1Head)\n",
    "blc2Head = np.array(blc2Head)\n",
    "blc3Head = np.array(blc3Head)\n",
    "blc4Head = np.array(blc4Head)\n",
    "blc5Head = np.array(blc5Head)\n",
    "blc6Head = np.array(blc6Head)\n",
    "blc7Head = np.array(blc7Head)\n",
    "blc8Head = np.array(blc8Head)\n",
    "\n",
    "# Check if files from respective blocks have the same head\n",
    "def checkCols(col):\n",
    "    return(all(x == col[0] for x in col))\n",
    "\n",
    "chk1 = all(np.apply_along_axis(checkCols, 0, blc1Head))\n",
    "chk2 = all(np.apply_along_axis(checkCols, 0, blc2Head))\n",
    "chk3 = all(np.apply_along_axis(checkCols, 0, blc3Head))\n",
    "chk4 = all(np.apply_along_axis(checkCols, 0, blc4Head))\n",
    "chk5 = all(np.apply_along_axis(checkCols, 0, blc5Head))\n",
    "chk6 = all(np.apply_along_axis(checkCols, 0, blc6Head))\n",
    "chk7 = all(np.apply_along_axis(checkCols, 0, blc7Head))\n",
    "chk8 = all(np.apply_along_axis(checkCols, 0, blc8Head))\n",
    "\n",
    "print(chk1, chk2, chk3, chk4, chk5, chk6, chk7, chk8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True True True True True True\n"
     ]
    }
   ],
   "source": [
    "# Check columns conformity for PL type\n",
    "\n",
    "blcHead = []\n",
    "\n",
    "\n",
    "for f in unzFiles:\n",
    "    s = f.split('_')\n",
    "    \n",
    "    # Type (BLC or PL)\n",
    "    fType = s[2]\n",
    "    \n",
    "    # For PL type\n",
    "    if fType == 'PL':\n",
    "        \n",
    "        # Year\n",
    "        fYear = s[3].split('.')[0]\n",
    "        \n",
    "        if len(fYear) == 4: # Year <= 2017\n",
    "            fMonth = None\n",
    "            fYear = int(fYear)\n",
    "        \n",
    "        else: # Year = 2018\n",
    "            fMonth = int(fYear[-2:])\n",
    "            fYear = int(fYear[:4])\n",
    "        \n",
    "        # Read file head\n",
    "        df_ = pd.read_csv(unzipTemp + f, sep = ';', \n",
    "                 encoding = 'ISO-8859-1', \n",
    "                 low_memory = False, \n",
    "                 nrows = 1)\n",
    "        \n",
    "        # Append head to respective block\n",
    "        blcHead.append(list(df_.keys()))\n",
    "\n",
    "\n",
    "# Arrange\n",
    "blcHead = np.array(blcHead)\n",
    "\n",
    "# # Check if files from respective blocks have the same head\n",
    "def checkCols(col):\n",
    "    return(all(x == col[0] for x in col))\n",
    "\n",
    "chk = all(np.apply_along_axis(checkCols, 0, blcHead))\n",
    "\n",
    "print(chk1, chk2, chk3, chk4, chk5, chk6, chk7, chk8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLC data:\n",
      "8 2005 None\n",
      "8 2006 None\n",
      "8 2007 None\n",
      "8 2008 None\n",
      "8 2009 None\n",
      "8 2010 None\n",
      "8 2011 None\n",
      "8 2012 None\n",
      "8 2013 None\n",
      "8 2014 None\n",
      "8 2015 None\n",
      "8 2016 None\n",
      "8 2017 None\n",
      "8 2018 1\n",
      "8 2018 2\n",
      "8 2018 3\n",
      "8 2018 4\n",
      "8 2018 5\n",
      "8 2018 6\n",
      "8 2018 7\n",
      "8 2018 8\n"
     ]
    }
   ],
   "source": [
    "# Create directory to save structured data\n",
    "if not os.path.exists(strucPath):\n",
    "    os.makedirs(strucPath)\n",
    "\n",
    "    # Read BLC files, append blocks in dataframes and save\n",
    "    print('BLC data:')\n",
    "    for blk in range(8, 8+1):\n",
    "        dfBlk = readBlcBlock(blk = blk, folder = unzipTemp)\n",
    "        print(blk, dfBlk.shape)\n",
    "        dfBlk.to_pickle(strucPath + 'BLC_blk_' + str(blk) + '_.pkl')\n",
    "    \n",
    "else:\n",
    "    print('Error: folder already existis.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read PL files, append blocks in dataframes and save\n",
    "dfPL = readPL(folder = unzipTemp)\n",
    "print(dfPL.shape)\n",
    "dfPL.to_pickle(strucPath + 'PL_.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete temporary unziped files and folder\n",
    "shutil.rmtree(unzipTemp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
